{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 300\n",
    "n_head = 4\n",
    "gen_results = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    return x.split()\n",
    "\n",
    "def embed(x):\n",
    "    embeddings = wv[x]\n",
    "    return embeddings\n",
    "\n",
    "def posEncode(x):\n",
    "    n_seq, _ = x.shape\n",
    "    i = np.arange(0, d_model, 2, dtype='float32')\n",
    "    denominator = np.power(10000, i/d_model)\n",
    "    position = np.arange(0, n_seq, dtype='float32').reshape(-1,1)\n",
    "    even_PE = np.sin(position / denominator)\n",
    "    odd_PE  = np.cos(position / denominator)\n",
    "    return x + np.ravel([even_PE.T, odd_PE.T],'F').reshape(n_seq, d_model)\n",
    "\n",
    "def masking(x):\n",
    "    mask = np.tril(np.ones((x.shape)))\n",
    "    mask[mask==0] = -np.infty\n",
    "    mask[mask==1] = 0\n",
    "    x = x + mask\n",
    "    return x\n",
    "\n",
    "def init_QKV():\n",
    "    #used once only\n",
    "    Q, K, V = [],[],[]\n",
    "    for h in range(n_head):\n",
    "        Q.append(np.random.rand(d_model, d_model//n_head))\n",
    "        K.append(np.random.rand(d_model, d_model//n_head))\n",
    "        V.append(np.random.rand(d_model, d_model//n_head))\n",
    "    return Q, K, V\n",
    "\n",
    "def context(input, Q,K,V, mask=False):    \n",
    "    context = []\n",
    "    for h in range(n_head):\n",
    "        raw_attention = (input @ Q[h]) @ (input @ K[h]).T\n",
    "        if (mask == True):\n",
    "            raw_attention = masking(raw_attention)\n",
    "        score = tf.nn.softmax(raw_attention / (d_model)** .5)\n",
    "        context.append(score @ (input @ V[h]))\n",
    "    concat = np.concatenate([c for c in context], axis=1)    \n",
    "    return concat\n",
    "\n",
    "def add_norm(context, prev_input, gamma, beta):\n",
    "    context = context + prev_input\n",
    "    mean = context.mean(axis=1).reshape(-1,1)\n",
    "    sigma = context.std(axis=1).reshape(-1,1)\n",
    "    context = (context - mean) / sigma\n",
    "    context = context * gamma + beta\n",
    "    return context\n",
    "\n",
    "def feed_forward(context, w, b):\n",
    "    #Assume no hidden layer\n",
    "    context = context @ w + b\n",
    "    context = tf.nn.relu(context).numpy()\n",
    "    return context\n",
    "\n",
    "\n",
    "def cross_context(input_e, input_d, Q_d,K_e,V_e):    \n",
    "    context = []\n",
    "    for h in range(n_head):\n",
    "        raw_attention = (input_d @ Q_d[h]) @ (input_e @ K_e[h]).T\n",
    "        score = tf.nn.softmax(raw_attention / (d_model)** .5)\n",
    "        context.append(score @ (input_e @ V_e[h]))\n",
    "\n",
    "    concat = np.concatenate([c for c in context], axis=1)    \n",
    "    return concat\n",
    "\n",
    "def Encode(sentence):\n",
    "    tokens = tokenize(sentence)\n",
    "    embeddings = embed(tokens)\n",
    "    input = posEncode(embeddings)\n",
    "    \n",
    "    Q,K,V = init_QKV()\n",
    "\n",
    "    context1 = context(input, Q,K,V)\n",
    "\n",
    "    gamma1 = np.random.rand(d_model) - 0.5\n",
    "    beta1 = np.random.rand(d_model) - 0.5\n",
    "\n",
    "    gamma2 = np.random.rand(d_model) - 0.5\n",
    "    beta2 = np.random.rand(d_model) - 0.5\n",
    "\n",
    "    w1 = np.random.rand(d_model, d_model) -0.5\n",
    "    b1 = np.random.rand(d_model) -0.5\n",
    "\n",
    "    context2 = add_norm(context1, input, gamma1, beta1)\n",
    "    context3 = feed_forward(context2, w1, b1)\n",
    "    context4 = add_norm(context3, context2, gamma2, beta2)\n",
    "\n",
    "    return context4\n",
    "\n",
    "\n",
    "Q_d, K_d, V_d = init_QKV()\n",
    "Q_d, K_e, V_e = init_QKV()\n",
    "gamma_d_1 = np.random.rand(d_model) - 0.5\n",
    "beta_d_1 = np.random.rand(d_model)  - 0.5\n",
    "gamma_d_2 = np.random.rand(d_model) - 0.5\n",
    "beta_d_2 = np.random.rand(d_model) - 0.5\n",
    "w2 = np.random.rand(d_model, d_model) - 0.5\n",
    "b2 = np.random.rand(d_model) - 0.5\n",
    "gamma_d_3 = np.random.rand(d_model) - 0.5\n",
    "beta_d_3 = np.random.rand(d_model) - 0.5\n",
    "w_linear = np.random.rand(d_model, gen_results) - 0.5\n",
    "b_linear = np.random.rand(gen_results) - 0.5\n",
    "\n",
    "def Decode(sentence2, context4, max_seq):\n",
    "\n",
    "    input2 = posEncode(embed(tokenize(sentence2))) #residual for the next addNorm\n",
    "    context_d_1 = context(input2, Q_d, K_d, V_d, mask=True)\n",
    "    context_d_2 = add_norm(context_d_1, input2, gamma_d_1, beta_d_1) #residual for the next addNorm\n",
    "    cross = cross_context(context4, context_d_2, Q_d, K_e, V_e)\n",
    "    context_d_3 = add_norm(context_d_2, cross, gamma_d_2, beta_d_2) #residual for the next addNorm\n",
    "    context_d_4 = feed_forward(context_d_3, w2, b2)\n",
    "    context_d_5 = add_norm(context_d_4, context_d_3, gamma_d_3, beta_d_3)\n",
    "    raw_prediction = context_d_5 @ w_linear + b_linear\n",
    "    prediction = tf.nn.softmax(raw_prediction)\n",
    "    out = wv.index_to_key[np.argmax(prediction)]\n",
    "    sentence2 = sentence2 + f\" {out}\"\n",
    "\n",
    "    if max_seq == 0:\n",
    "        print(sentence2)\n",
    "        return\n",
    "\n",
    "    Decode(sentence2, context4, max_seq - 1)\n",
    "\n",
    "def Generate(sentence, max_seq):\n",
    "    context4 = Encode(sentence)\n",
    "    Decode('</s>', context4, max_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> by by by by by by\n"
     ]
    }
   ],
   "source": [
    "Generate('wassup', max_seq=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
